{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a409700",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b283f812",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autokeras.keras_layers import ExpandLastDim\n",
    "from autokeras.keras_layers import CastToFloat32\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, GlobalMaxPooling2D, GlobalAveragePooling2D, LSTM, SimpleRNN\n",
    "from tensorflow.keras.layers import InputLayer, Dense, Flatten, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from tensorflow.keras.layers.experimental.preprocessing import RandomTranslation, RandomFlip\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Resizing\n",
    "from tensorflow.keras.layers import Concatenate\n",
    "from tensorflow.keras.applications import EfficientNetB7\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "gpu_devices = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "for device in gpu_devices:\n",
    "    tf.config.experimental.set_memory_growth(device, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bfcb936",
   "metadata": {},
   "source": [
    "# Make Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d959d193",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def calculateWeight(tlx):\n",
    "    tlx_weight = {'Mental':[0], \n",
    "                  'Physical':[0], \n",
    "                  'Temporal':[0], \n",
    "                  'Effort':[0],\n",
    "                  'Performance':[0],\n",
    "                  'Frustration':[0],\n",
    "                  'Sum':[0]}\n",
    "    tlx_weight = pd.DataFrame(tlx_weight)\n",
    "    for i in range(len(tlx)):\n",
    "        score = [0,0,0,0,0,0,0]\n",
    "        for col1 in range(1,len(tlx.columns)):\n",
    "            for col2 in range(col1+1, len(tlx.columns)):\n",
    "                if tlx[tlx.columns[col1]][i] > tlx[tlx.columns[col2]][i]:\n",
    "                    score[col1-1]+=1\n",
    "                elif tlx[tlx.columns[col1]][i] < tlx[tlx.columns[col2]][i]:\n",
    "                    score[col2-1]+=1\n",
    "                else :\n",
    "                    score[col1-1]+=0.5\n",
    "                    score[col2-1]+=0.5\n",
    "                    \n",
    "        score[6] = score[0]+score[1]+score[2]+score[3]+score[4]+score[5]\n",
    "        tlx_weight.loc[i]=score\n",
    "    #print(tlx_weight.loc[0])\n",
    "    return tlx_weight\n",
    "\n",
    "def calculate_tlxLevel(tlx, tlx_weight):\n",
    "    result = {'Mental':[0], \n",
    "                  'Physical':[0], \n",
    "                  'Temporal':[0], \n",
    "                  'Effort':[0],\n",
    "                  'Performance':[0],\n",
    "                  'Frustration':[0],\n",
    "                  'Score':[0]}\n",
    "    result = pd.DataFrame(result)\n",
    "    for i in range(len(tlx)):\n",
    "        score = [0,0,0,0,0,0,0]\n",
    "        for col in range(len(tlx_weight.columns)-1):\n",
    "            score[col] = int(tlx[tlx.columns[col+1]].loc[i] * tlx_weight[tlx_weight.columns[col]].loc[i] )\n",
    "        score[6] =int((score[0]+score[1]+score[2]+score[3]+score[4]+score[5] )/ tlx_weight[tlx_weight.columns[6]].loc[i]/10 + 0.5)\n",
    "        if score[6]>10: score[6]=10\n",
    "        if score[6]<0: score[6]=0\n",
    "        result.loc[i]=score\n",
    "    return result['Score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e83195eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "src = 'EEG data/User/'\n",
    "files = os.listdir(src)\n",
    "tlx=[]\n",
    "for f in files:\n",
    "    tlx.append(pd.read_csv(src+f))\n",
    "src = 'EEG data/prepross/'\n",
    "datas = os.listdir(src)\n",
    "workloadLevel = []\n",
    "for t in tlx:\n",
    "    workloadLevel.append(calculate_tlxLevel(t, calculateWeight(t)))\n",
    "eegData=[]\n",
    "for d in datas:\n",
    "    eegData.append(pd.read_csv(src+d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "aa71131a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_theta_alpha(df):\n",
    "    col = ['POW.AF3.Theta', 'POW.AF3.Alpha', 'POW.F7.Theta', 'POW.F7.Alpha', \n",
    "           'POW.F3.Theta', 'POW.F3.Alpha', 'POW.FC5.Theta', 'POW.FC5.Alpha', \n",
    "           'POW.T7.Theta', 'POW.T7.Alpha', 'POW.P7.Theta', 'POW.P7.Alpha',\n",
    "           'POW.O1.Theta', 'POW.O1.Alpha', 'POW.O2.Theta', 'POW.O2.Alpha', \n",
    "           'POW.P8.Theta', 'POW.P8.Alpha', 'POW.T8.Theta', 'POW.T8.Alpha',\n",
    "           'POW.FC6.Theta', 'POW.FC6.Alpha',  'POW.F4.Theta', 'POW.F4.Alpha', \n",
    "           'POW.F8.Theta', 'POW.F8.Alpha','POW.AF4.Theta', 'POW.AF4.Alpha','MarkerValueInt']\n",
    "    col_rename = ['AF3.Theta', 'AF3.Alpha', 'F7.Theta','F7.Alpha', \n",
    "                               'F3.Theta', 'F3.Alpha', 'FC5.Theta', 'FC5.Alpha', \n",
    "                               'T7.Theta', 'T7.Alpha', 'P7.Theta', 'P7.Alpha', \n",
    "                               'O1.Theta', 'O1.Alpha', 'O2.Theta', 'O2.Alpha',\n",
    "                               'P8.Theta', 'P8.Alpha', 'T8.Theta','T8.Alpha',\n",
    "                               'FC6.Theta', 'FC6.Alpha', 'F4.Theta', 'F4.Alpha', \n",
    "                               'F8.Theta', 'F8.Alpha', 'AF4.Theta', 'AF4.Alpha','vis_name']\n",
    "    col2 = ['AF3', 'F7','F3', 'FC5', 'T7', 'P7', 'O1', 'O2',\n",
    "            'P8', 'T8', 'FC6', 'F4', 'F8', 'AF4','vis_name']\n",
    "    data_extraction = df[col]\n",
    "    data_extraction.columns = col_rename\n",
    "    \n",
    "    for i in range(0,len(col2)-1):\n",
    "        data_extraction[col2[i]]=data_extraction[col_rename[2*i]]/data_extraction[col_rename[2*i+1]]\n",
    "    result = data_extraction[col2]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "175d5d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_theta_alpha_data(df, label, end):\n",
    "    data_extraction = cal_theta_alpha(df)\n",
    "    rest = data_extraction[data_extraction.vis_name == 0].dropna(axis=0)\n",
    "    survey = data_extraction[data_extraction.vis_name == 100].dropna(axis=0)\n",
    "    \n",
    "    vis = data_extraction[data_extraction.vis_name == 1].reset_index(drop=True).dropna(axis=0)\n",
    "    vis['label'] = label[0]\n",
    "    vis.drop(['vis_name'], axis=1, inplace=True)\n",
    "    \n",
    "    for i in range(2,end):\n",
    "        df = data_extraction[data_extraction.vis_name == i].reset_index(drop=True)\n",
    "        df['label'] = label[i-1]\n",
    "        df.drop(['vis_name'], axis=1, inplace=True)\n",
    "        df = df.dropna(axis=0)\n",
    "        vis = pd.concat([vis,df], ignore_index=True, axis=0)\n",
    "    return rest, survey, vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980e2714",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "for eeg, label in zip (eegData, workloadLevel):\n",
    "    if cnt == 0 :\n",
    "        rest, survey, vis = split_theta_alpha_data(eeg, label,21)\n",
    "        cnt+=1\n",
    "        continue\n",
    "    elif cnt == 6:\n",
    "        r, s, v = split_theta_alpha_data(eeg, label,21)\n",
    "    else:\n",
    "        r, s, v = split_theta_alpha_data(eeg, label, 22)\n",
    "    \n",
    "    rest = pd.concat([rest,r], ignore_index=True, axis=0)\n",
    "    survey = pd.concat([survey,s], ignore_index=True, axis=0)\n",
    "    vis = pd.concat([vis,v], ignore_index=True, axis=0)\n",
    "    cnt+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "89630300",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AF3</th>\n",
       "      <th>F7</th>\n",
       "      <th>F3</th>\n",
       "      <th>FC5</th>\n",
       "      <th>T7</th>\n",
       "      <th>P7</th>\n",
       "      <th>O1</th>\n",
       "      <th>O2</th>\n",
       "      <th>P8</th>\n",
       "      <th>T8</th>\n",
       "      <th>FC6</th>\n",
       "      <th>F4</th>\n",
       "      <th>F8</th>\n",
       "      <th>AF4</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.952833</td>\n",
       "      <td>3.105452</td>\n",
       "      <td>1.733649</td>\n",
       "      <td>1.286172</td>\n",
       "      <td>0.997657</td>\n",
       "      <td>1.123533</td>\n",
       "      <td>1.104817</td>\n",
       "      <td>1.036953</td>\n",
       "      <td>1.283992</td>\n",
       "      <td>1.757355</td>\n",
       "      <td>1.490719</td>\n",
       "      <td>1.281464</td>\n",
       "      <td>3.378006</td>\n",
       "      <td>2.528323</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.337757</td>\n",
       "      <td>3.067987</td>\n",
       "      <td>1.808938</td>\n",
       "      <td>1.269267</td>\n",
       "      <td>0.947180</td>\n",
       "      <td>1.063313</td>\n",
       "      <td>1.139223</td>\n",
       "      <td>0.986136</td>\n",
       "      <td>1.240326</td>\n",
       "      <td>1.668122</td>\n",
       "      <td>1.543780</td>\n",
       "      <td>1.290260</td>\n",
       "      <td>3.529764</td>\n",
       "      <td>2.448986</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.460255</td>\n",
       "      <td>2.889841</td>\n",
       "      <td>1.808787</td>\n",
       "      <td>1.317058</td>\n",
       "      <td>1.021541</td>\n",
       "      <td>1.094298</td>\n",
       "      <td>1.247150</td>\n",
       "      <td>1.009595</td>\n",
       "      <td>1.237751</td>\n",
       "      <td>1.655340</td>\n",
       "      <td>1.565374</td>\n",
       "      <td>1.313119</td>\n",
       "      <td>3.339320</td>\n",
       "      <td>2.115198</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.400069</td>\n",
       "      <td>2.708860</td>\n",
       "      <td>1.791900</td>\n",
       "      <td>1.424313</td>\n",
       "      <td>1.191386</td>\n",
       "      <td>1.205574</td>\n",
       "      <td>1.426901</td>\n",
       "      <td>1.120465</td>\n",
       "      <td>1.306624</td>\n",
       "      <td>1.768321</td>\n",
       "      <td>1.586444</td>\n",
       "      <td>1.378863</td>\n",
       "      <td>2.988018</td>\n",
       "      <td>1.751219</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.241047</td>\n",
       "      <td>2.532158</td>\n",
       "      <td>1.808551</td>\n",
       "      <td>1.631368</td>\n",
       "      <td>1.419774</td>\n",
       "      <td>1.379464</td>\n",
       "      <td>1.662086</td>\n",
       "      <td>1.299213</td>\n",
       "      <td>1.425712</td>\n",
       "      <td>1.995887</td>\n",
       "      <td>1.627646</td>\n",
       "      <td>1.480259</td>\n",
       "      <td>2.582288</td>\n",
       "      <td>1.432403</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108207</th>\n",
       "      <td>3.587874</td>\n",
       "      <td>4.357214</td>\n",
       "      <td>2.334554</td>\n",
       "      <td>2.569024</td>\n",
       "      <td>2.588199</td>\n",
       "      <td>0.650938</td>\n",
       "      <td>1.722900</td>\n",
       "      <td>1.677678</td>\n",
       "      <td>3.284874</td>\n",
       "      <td>77.501610</td>\n",
       "      <td>2.656741</td>\n",
       "      <td>2.109043</td>\n",
       "      <td>5.051498</td>\n",
       "      <td>4.562173</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108208</th>\n",
       "      <td>3.698659</td>\n",
       "      <td>4.904903</td>\n",
       "      <td>2.268399</td>\n",
       "      <td>2.620445</td>\n",
       "      <td>3.133342</td>\n",
       "      <td>0.698348</td>\n",
       "      <td>1.671146</td>\n",
       "      <td>1.395313</td>\n",
       "      <td>3.428622</td>\n",
       "      <td>68.175779</td>\n",
       "      <td>2.429011</td>\n",
       "      <td>1.763087</td>\n",
       "      <td>4.876154</td>\n",
       "      <td>4.746517</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108209</th>\n",
       "      <td>3.660792</td>\n",
       "      <td>5.359041</td>\n",
       "      <td>2.181249</td>\n",
       "      <td>2.608695</td>\n",
       "      <td>4.296135</td>\n",
       "      <td>0.733687</td>\n",
       "      <td>1.795107</td>\n",
       "      <td>1.197751</td>\n",
       "      <td>3.339025</td>\n",
       "      <td>62.193847</td>\n",
       "      <td>2.148419</td>\n",
       "      <td>1.510463</td>\n",
       "      <td>4.708856</td>\n",
       "      <td>4.880381</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108210</th>\n",
       "      <td>3.514900</td>\n",
       "      <td>5.855391</td>\n",
       "      <td>2.066605</td>\n",
       "      <td>2.640225</td>\n",
       "      <td>5.978087</td>\n",
       "      <td>0.750709</td>\n",
       "      <td>2.052408</td>\n",
       "      <td>1.085270</td>\n",
       "      <td>3.014408</td>\n",
       "      <td>61.070530</td>\n",
       "      <td>1.819241</td>\n",
       "      <td>1.322830</td>\n",
       "      <td>4.551947</td>\n",
       "      <td>4.934379</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108211</th>\n",
       "      <td>3.256350</td>\n",
       "      <td>6.710074</td>\n",
       "      <td>1.864572</td>\n",
       "      <td>2.810063</td>\n",
       "      <td>6.833577</td>\n",
       "      <td>0.723416</td>\n",
       "      <td>2.378548</td>\n",
       "      <td>1.049911</td>\n",
       "      <td>2.490740</td>\n",
       "      <td>65.327507</td>\n",
       "      <td>1.460841</td>\n",
       "      <td>1.164617</td>\n",
       "      <td>4.417606</td>\n",
       "      <td>4.980039</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108212 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             AF3        F7        F3       FC5        T7        P7        O1  \\\n",
       "0       2.952833  3.105452  1.733649  1.286172  0.997657  1.123533  1.104817   \n",
       "1       3.337757  3.067987  1.808938  1.269267  0.947180  1.063313  1.139223   \n",
       "2       3.460255  2.889841  1.808787  1.317058  1.021541  1.094298  1.247150   \n",
       "3       3.400069  2.708860  1.791900  1.424313  1.191386  1.205574  1.426901   \n",
       "4       3.241047  2.532158  1.808551  1.631368  1.419774  1.379464  1.662086   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "108207  3.587874  4.357214  2.334554  2.569024  2.588199  0.650938  1.722900   \n",
       "108208  3.698659  4.904903  2.268399  2.620445  3.133342  0.698348  1.671146   \n",
       "108209  3.660792  5.359041  2.181249  2.608695  4.296135  0.733687  1.795107   \n",
       "108210  3.514900  5.855391  2.066605  2.640225  5.978087  0.750709  2.052408   \n",
       "108211  3.256350  6.710074  1.864572  2.810063  6.833577  0.723416  2.378548   \n",
       "\n",
       "              O2        P8         T8       FC6        F4        F8       AF4  \\\n",
       "0       1.036953  1.283992   1.757355  1.490719  1.281464  3.378006  2.528323   \n",
       "1       0.986136  1.240326   1.668122  1.543780  1.290260  3.529764  2.448986   \n",
       "2       1.009595  1.237751   1.655340  1.565374  1.313119  3.339320  2.115198   \n",
       "3       1.120465  1.306624   1.768321  1.586444  1.378863  2.988018  1.751219   \n",
       "4       1.299213  1.425712   1.995887  1.627646  1.480259  2.582288  1.432403   \n",
       "...          ...       ...        ...       ...       ...       ...       ...   \n",
       "108207  1.677678  3.284874  77.501610  2.656741  2.109043  5.051498  4.562173   \n",
       "108208  1.395313  3.428622  68.175779  2.429011  1.763087  4.876154  4.746517   \n",
       "108209  1.197751  3.339025  62.193847  2.148419  1.510463  4.708856  4.880381   \n",
       "108210  1.085270  3.014408  61.070530  1.819241  1.322830  4.551947  4.934379   \n",
       "108211  1.049911  2.490740  65.327507  1.460841  1.164617  4.417606  4.980039   \n",
       "\n",
       "        label  \n",
       "0           6  \n",
       "1           6  \n",
       "2           6  \n",
       "3           6  \n",
       "4           6  \n",
       "...       ...  \n",
       "108207      5  \n",
       "108208      5  \n",
       "108209      5  \n",
       "108210      5  \n",
       "108211      5  \n",
       "\n",
       "[108212 rows x 15 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "baaa88c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(108212, 14) (108212, 11)\n"
     ]
    }
   ],
   "source": [
    "label=vis['label']\n",
    "label = to_categorical(label,11)\n",
    "data=vis.drop(['label'],axis=1)\n",
    "scaler = MinMaxScaler()\n",
    "scaled = scaler.fit_transform(data)\n",
    "data = pd.DataFrame(scaled, columns = data.columns, index=data.index)\n",
    "data\n",
    "print(data.shape, label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2e13c048",
   "metadata": {},
   "outputs": [],
   "source": [
    "def windowing_dataset(data, label, window_size):\n",
    "    data_list = []\n",
    "    label_list = []\n",
    "    \n",
    "    for i in range(0,len(data)//window_size,window_size):\n",
    "        data_list.append(np.array(data.iloc[i:i+window_size]))\n",
    "        label_list.append(np.array(label.iloc[i]))\n",
    "    return np.array(data_list), np.array(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "38cb9187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(331, 14, 14) (222, 14, 14) (331, 11) (222, 11)\n"
     ]
    }
   ],
   "source": [
    "x, y = windowing_dataset(data,pd.DataFrame(label),14)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, train_size=0.6, \n",
    "                                                    random_state=True,\n",
    "                                                    stratify = y)\n",
    "\n",
    "print(x_train.shape, x_test.shape,y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ec0f355",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def drawResult(history):\n",
    "    fig, loss_ax = plt.subplots()\n",
    "    acc_ax = loss_ax.twinx()\n",
    "\n",
    "    loss_ax.plot(history.history['loss'], 'y', label='train loss')\n",
    "    loss_ax.plot(history.history['val_loss'], 'r', label='val loss')\n",
    "    loss_ax.set_xlabel('epoch')\n",
    "    loss_ax.set_ylabel('loss')\n",
    "    loss_ax.legend(loc='upper left')\n",
    "\n",
    "    acc_ax.plot(history.history['accuracy'], 'b', label='train acc')\n",
    "    acc_ax.plot(history.history['val_accuracy'], 'g', label='val acc')\n",
    "    acc_ax.set_ylabel('accuracy')\n",
    "    acc_ax.legend(loc='upper left')\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "def runModel(model, crossentropy, x_train, y_train, x_valid, y_valid):\n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=10)\n",
    "    model.compile(optimizer='adam', loss= crossentropy, metrics='accuracy')\n",
    "\n",
    "    history = model.fit(x_train, y_train, \n",
    "                        epochs = 200, \n",
    "                        validation_data = (x_valid, y_valid), \n",
    "                        callbacks=[early_stop], verbose=1)\n",
    "    drawResult(history)\n",
    "    return model\n",
    "\n",
    "def eval_model(model, x_test, y_test):\n",
    "    y_pred = model.predict(x_test)\n",
    "    return f1_score(y_test.argmax(axis=1), y_pred.argmax(axis=1), average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c9e6765",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Model2_2_1():\n",
    "    model = Sequential()\n",
    "    model.add(InputLayer(input_shape=(14, 14)))\n",
    "    model.add(ExpandLastDim())\n",
    "    model.add(CastToFloat32())\n",
    "    \n",
    "    model.add(Conv2D(512, kernel_size=(4,4), strides=(1,1), activation='relu', padding='valid'))\n",
    "    model.add(Conv2D(512, kernel_size=(4,4), strides=(1,1), activation='relu', padding='valid'))\n",
    "    model.add(MaxPooling2D(2,2))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Dense(11, activation='sigmoid'))\n",
    "    \n",
    "    #model.summary()\n",
    "    return model\n",
    "\n",
    "def Model2_2_2():\n",
    "    model = Sequential()\n",
    "    model.add(InputLayer(input_shape=(14, 14)))\n",
    "    model.add(ExpandLastDim())\n",
    "    model.add(CastToFloat32())\n",
    "    \n",
    "    model.add(Conv2D(512, kernel_size=(2,2), strides=(1,1), activation='relu', padding='valid'))\n",
    "    model.add(Conv2D(512, kernel_size=(2,2), strides=(1,1), activation='relu', padding='valid'))\n",
    "    model.add(MaxPooling2D(2,2))\n",
    "    \n",
    "    model.add(Conv2D(128, kernel_size=(2,2), strides=(1,1), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(128, kernel_size=(2,2), strides=(1,1), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D(2,2))\n",
    "    \n",
    "    model.add(Conv2D(32, kernel_size=(2,2), strides=(1,1), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(32, kernel_size=(2,2), strides=(1,1), activation='relu', padding='same'))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(11, activation='sigmoid'))\n",
    "    \n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "def Model2_2_3():\n",
    "    model = Sequential()\n",
    "    model.add(InputLayer(input_shape=(14, 14)))\n",
    "    model.add(ExpandLastDim())\n",
    "    model.add(CastToFloat32())\n",
    "    \n",
    "    model.add(Conv2D(512, kernel_size=(4,4), strides=(1,1), activation='relu', padding='valid'))\n",
    "    model.add(Conv2D(512, kernel_size=(4,4), strides=(1,1), activation='relu', padding='valid'))\n",
    "    model.add(MaxPooling2D(2,2))\n",
    "    \n",
    "    model.add(Conv2D(128, kernel_size=(4,4), strides=(1,1), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(128, kernel_size=(4,4), strides=(1,1), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D(2,2))\n",
    "    \n",
    "    model.add(Conv2D(32, kernel_size=(4,4), strides=(1,1), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(32, kernel_size=(4,4), strides=(1,1), activation='relu', padding='same'))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(11, activation='sigmoid'))\n",
    "    \n",
    "    #model.summary()\n",
    "    return model\n",
    "\n",
    "crossentropy = 'categorical_crossentropy'\n",
    "\n",
    "print(eval_model(runModel(Model2_2_1(),crossentropy,\n",
    "                          x_train, y_train, x_valid, y_valid), x_test, y_test))\n",
    "print(eval_model(runModel(Model2_2_2(),crossentropy,\n",
    "                          x_train, y_train, x_valid, y_valid), x_test, y_test))\n",
    "print(eval_model(runModel(Model2_2_3(),crossentropy,\n",
    "                          x_train, y_train, x_valid, y_valid), x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a10617",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Model2_1_1():\n",
    "    model = Sequential()\n",
    "    model.add(InputLayer(input_shape=(14, 14)))\n",
    "    model.add(ExpandLastDim())\n",
    "    model.add(CastToFloat32())\n",
    "    \n",
    "    model.add(Conv2D(512, kernel_size=(4,4), strides=(1,1), activation='relu', padding='valid'))\n",
    "    model.add(Conv2D(512, kernel_size=(4,4), strides=(1,1), activation='relu', padding='valid'))\n",
    "    model.add(MaxPooling2D(2,2))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Dense(11, activation='sigmoid'))\n",
    "    \n",
    "    #model.summary()\n",
    "    return model\n",
    "\n",
    "def Model2_1_2():\n",
    "    model = Sequential()\n",
    "    model.add(InputLayer(input_shape=(14, 14)))\n",
    "    model.add(ExpandLastDim())\n",
    "    model.add(CastToFloat32())\n",
    "    \n",
    "    model.add(Conv2D(512, kernel_size=(2,2), strides=(1,1), activation='relu', padding='valid'))\n",
    "    model.add(Conv2D(512, kernel_size=(2,2), strides=(1,1), activation='relu', padding='valid'))\n",
    "    model.add(MaxPooling2D(2,2))\n",
    "    \n",
    "    model.add(Conv2D(128, kernel_size=(2,2), strides=(1,1), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(128, kernel_size=(2,2), strides=(1,1), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D(2,2))\n",
    "    \n",
    "    model.add(Conv2D(32, kernel_size=(2,2), strides=(1,1), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(32, kernel_size=(2,2), strides=(1,1), activation='relu', padding='same'))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(11, activation='sigmoid'))\n",
    "    \n",
    "    #model.summary()\n",
    "    return model\n",
    "\n",
    "def Model2_1_3():\n",
    "    model = Sequential()\n",
    "    model.add(InputLayer(input_shape=(14, 14)))\n",
    "    model.add(ExpandLastDim())\n",
    "    model.add(CastToFloat32())\n",
    "    \n",
    "    model.add(Conv2D(512, kernel_size=(4,4), strides=(1,1), activation='relu', padding='valid'))\n",
    "    model.add(Conv2D(512, kernel_size=(4,4), strides=(1,1), activation='relu', padding='valid'))\n",
    "    model.add(MaxPooling2D(2,2))\n",
    "    \n",
    "    model.add(Conv2D(128, kernel_size=(4,4), strides=(1,1), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(128, kernel_size=(4,4), strides=(1,1), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D(2,2))\n",
    "    \n",
    "    model.add(Conv2D(32, kernel_size=(4,4), strides=(1,1), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(32, kernel_size=(4,4), strides=(1,1), activation='relu', padding='same'))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(11, activation='sigmoid'))\n",
    "    \n",
    "    #model.summary()\n",
    "    return model\n",
    "\n",
    "crossentropy = 'categorical_crossentropy'\n",
    "\n",
    "print(eval_model(runModel(Model2_1_1(),crossentropy,\n",
    "                          x_train, y_train, x_valid, y_valid), x_test, y_test))\n",
    "print(eval_model(runModel(Model2_1_2(),crossentropy,\n",
    "                          x_train, y_train, x_valid, y_valid), x_test, y_test))\n",
    "print(eval_model(runModel(Model2_1_3(),crossentropy,\n",
    "                          x_train, y_train, x_valid, y_valid), x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf544e8",
   "metadata": {},
   "source": [
    "# AUTO KERAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3994b3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import autokeras as ak\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "46b97b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1083, 10, 70) (1083, 11)\n",
      "(649, 10, 70) (434, 10, 70) (649, 11) (434, 11)\n"
     ]
    }
   ],
   "source": [
    "x_fft, y_fft = windowing_dataset(data_fft,pd.DataFrame(label_fft),10)\n",
    "print(x_fft.shape, y_fft.shape)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_fft,y_fft, train_size=0.6, \n",
    "                                                    random_state=True,\n",
    "                                                    stratify = y_fft)\n",
    "\n",
    "print(x_train.shape, x_test.shape,y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ddc034",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1 Complete [00h 00m 06s]\n",
      "val_loss: 0.955339252948761\n",
      "\n",
      "Best val_loss So Far: 0.955339252948761\n",
      "Total elapsed time: 00h 00m 06s\n",
      "\n",
      "Search: Running Trial #2\n",
      "\n",
      "Hyperparameter    |Value             |Best Value So Far \n",
      "image_block_1/b...|resnet            |vanilla           \n",
      "image_block_1/n...|True              |True              \n",
      "image_block_1/a...|True              |False             \n",
      "image_block_1/i...|True              |None              \n",
      "image_block_1/i...|True              |None              \n",
      "image_block_1/i...|0                 |None              \n",
      "image_block_1/i...|0                 |None              \n",
      "image_block_1/i...|0.1               |None              \n",
      "image_block_1/i...|0                 |None              \n",
      "image_block_1/r...|False             |None              \n",
      "image_block_1/r...|resnet50          |None              \n",
      "image_block_1/r...|True              |None              \n",
      "classification_...|global_avg        |flatten           \n",
      "classification_...|0                 |0.5               \n",
      "optimizer         |adam              |adam              \n",
      "learning_rate     |0.001             |0.001             \n",
      "\n",
      "Epoch 1/20\n",
      "17/17 [==============================] - 17s 578ms/step - loss: 2.1954 - accuracy: 0.3180 - val_loss: 2308.2114 - val_accuracy: 0.4095\n",
      "Epoch 2/20\n",
      " 5/17 [=======>......................] - ETA: 5s - loss: 1.4015 - accuracy: 0.3125"
     ]
    }
   ],
   "source": [
    "trials=[3] #,5,10,20]\n",
    "for trial in trials:\n",
    "    clf_ = ak.ImageClassifier(overwrite=True, max_trials=trial)\n",
    "    clf_.fit(x=x_train, y=y_train, epochs=20)\n",
    "\n",
    "    predicted_y = clf_.predict(x_test)\n",
    "    print(predicted_y)\n",
    "    loss, acc = clf_.evaluate(x_test, y_test)\n",
    "    print(clf_.evaluate(x_test, y_test))\n",
    "    print('Loss: %.3f   Accuracy: %.3f' % (loss,acc))\n",
    "\n",
    "    model = clf_.export_model()\n",
    "    model.summary()\n",
    "    plot_model(model, show_shapes=True)\n",
    "    tmp = int(acc*100)\n",
    "    print(tmp)\n",
    "    model.save('model/'+'_ACC_'+str(tmp)+'_try_'+str(trial)+'_.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afac19f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
